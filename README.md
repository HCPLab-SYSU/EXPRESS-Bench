# Fine-EQA
Embodied Question Answering (EQA) benchmark and method

**Multimodal Embodied Interaction in Unknown Environments: A Benchmark and Method**        
For more details, please refer to our paper [Multimodal Embodied Interaction in Unknown Environments: A Benchmark and Method](https://arxiv.org/pdf/2402.00290)       

### Abstract

With the surge in the development of large language models, embodied intelligence has attracted increasing attention. Nevertheless, prior works on embodied intelligence typically encode scene or historical memory in an unimodal manner, either visual or linguistic, which complicates the alignment of the model's action planning with embodied control. To overcome this limitation, we introduce the Multimodal Embodied Interactive Agent (MEIA), capable of translating high-level tasks expressed in natural language into a sequence of executable actions. Specifically, we propose a novel Multimodal Environment Memory (MEM) module, facilitating the integration of embodied control with large models through the visual-language memory of scenes. This capability enables MEIA to generate executable action plans based on diverse requirements and the robotâ€™s capabilities. 
Furthermore, we construct an embodied question answering dataset based on a dynamic virtual cafe environment with the help of the large language model. In this virtual environment, we conduct several experiments, utilizing multiple large models through zero-shot learning, and carefully design scenarios for various situations. 
The experimental results showcase the promising performance of our MEIA in various embodied interactive tasks.

### Fine-EQA Dataset and MEIA models

We will release them as soon as possible!

### Citation
If you use this code for your research, please cite our paper.      
```
@article{liu2024multimodal,
  title={Multimodal Embodied Interactive Agent for Cafe Scene},
  author={Liu, Yang and Song, Xinshuai and Jiang, Kaixuan and Chen, Weixing and Luo, Jingzhou and Li, Guanbin and Lin, Liang},
  journal={arXiv preprint arXiv:2402.00290},
  year={2024}
}

``` 
If you have any question about this code, feel free to reach (liuy856@mail.sysu.edu.cn). 
